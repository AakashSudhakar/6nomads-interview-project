{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Intermediate Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we conclude our end-to-end data pipeline through a **predictive** lens: we apply classical machine learning models and algorithms to assess predictive accuracies for our training and testing data. \n",
    "\n",
    "- **NOTE**: Before working through this notebook, please ensure that you have all necessary dependencies as denoted in [Section A: Imports and Initializations](#section-A) of this notebook.\n",
    "\n",
    "- **NOTE**: Before working through Sections A-D of this notebook, please run all code cells in [Appendix A: Supplementary Custom Objects](#appendix-A) to ensure that all relevant functions and objects are appropriately instantiated and ready for use.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”µ TABLE OF CONTENTS ðŸ”µ <a name=\"TOC\"></a>\n",
    "\n",
    "Use this **table of contents** to navigate the various sections of the processing notebook.\n",
    "\n",
    "#### 1. [Section A: Imports and Initializations](#section-A)\n",
    "\n",
    "    All necessary imports and object instantiations for data predictions.\n",
    "\n",
    "#### 2. [Section B: Loading our Processed Data](#section-B)\n",
    "\n",
    "    Loading processed data states for current access.\n",
    "\n",
    "#### 3. [Section C: Machine Learning](#section-C)\n",
    "\n",
    "    Applying classical machine learning algorithms on processed datasets.\n",
    "    \n",
    "#### 4. [Section D: Deep Learning](#section-D)\n",
    "\n",
    "    Applying advanced machine learning and deep learning algorithms on processed datasets. \n",
    "\n",
    "#### 5. [Appendix A: Supplementary Custom Objects](#appendix-A)\n",
    "\n",
    "    Custom Python object architectures used throughout the data processing.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section A: Imports and Initializations <a name=\"section-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Importations for Data Manipulation and Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules for Data Preparation and Model Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms for Data Resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakashsudhakar/anaconda3/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms for Classical Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Algorithmic Support Structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../structures/\")\n",
    "from custom_structures import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section B: Loading our Processed Data <a name=\"section-B\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PATH_PROC_DATA = \"../data/processed/\"\n",
    "DATA_X, DATA_y = \"X/\", \"y/\"\n",
    "SUBDIR_PROC, SUBDIR_SCA, SUBDIR_RED = \"processed/\", \"scaled/\", \"reduced/\"\n",
    "\n",
    "X_TRAIN_PROC, X_TEST_PROC = \"train_pXp.csv\", \"test_pXp.csv\"\n",
    "X_TRAIN_SCA, X_TEST_SCA = \"train_pXs.csv\", \"test_pXs.csv\"\n",
    "X_TRAIN_RED, X_TEST_RED = \"train_pXr.csv\", \"test_pXr.csv\"\n",
    "y_TRAIN_PROC, y_TEST_PROC = \"train_pyp.csv\", \"test_pyp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data: _Fully Processed X-Datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pro = pd.read_csv(REL_PATH_PROC_DATA + DATA_X + SUBDIR_PROC + X_TRAIN_PROC, index_col=0)\n",
    "X_test_pro = pd.read_csv(REL_PATH_PROC_DATA + DATA_X + SUBDIR_PROC + X_TEST_PROC, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data: _Scaled X-Datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sca = pd.read_csv(REL_PATH_PROC_DATA + DATA_X + SUBDIR_SCA + X_TRAIN_SCA, index_col=0)\n",
    "X_test_sca = pd.read_csv(REL_PATH_PROC_DATA + DATA_X + SUBDIR_SCA + X_TEST_SCA, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data: _Dimensionally Reduced X-Datasets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red = pd.read_csv(REL_PATH_PROC_DATA + DATA_X + SUBDIR_RED + X_TRAIN_RED, index_col=0)\n",
    "X_test_red = pd.read_csv(REL_PATH_PROC_DATA + DATA_X + SUBDIR_RED + X_TEST_RED, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data: _Fully Processed Targets (y)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pro = np.ravel(pd.read_csv(REL_PATH_PROC_DATA + DATA_y + SUBDIR_PROC + y_TRAIN_PROC, index_col=0, header=None))\n",
    "y_test_pro = np.ravel(pd.read_csv(REL_PATH_PROC_DATA + DATA_y + SUBDIR_PROC + y_TEST_PROC, index_col=0, header=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section C: Machine Learning <a name=\"section-C\"></a>\n",
    "\n",
    "#### Models to Use:\n",
    "- **k-Nearest Neighbors Classifier**\n",
    "    - _Hyperparameters_: `n_neighbors`, ~~`leaf_size`~~, `weights`, ~~`algorithm`~~\n",
    "- ~~**Support Vector Classifier**~~\n",
    "    - ~~_Hyperparameters_: `kernel`, `C`, `gamma`, `degree`~~\n",
    "- **Decision Tree Classifier**\n",
    "    - _Hyperparameters_: ~~`max_features`~~, `min_samples_split`, `min_samples_leaf`\n",
    "- **Random Forest Classifier**\n",
    "    - _Hyperparameters_: ~~`criterion`~~, ~~`n_estimators`~~, `min_samples_split`, `min_samples_leaf`\n",
    "- **Logistic Regression Classifier**\n",
    "    - _Hyperparameters_: `penalty`, `C`\n",
    "    \n",
    "_TODO_: Explore mechanics behind SVM dysfunction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Optimal Hyperparameters for Conducting Cross-Validation-Driven Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparams = {\n",
    "    \"kNN\": (KNeighborsClassifier, {\n",
    "        \"n_neighbors\": [1, 3, 5],\n",
    "#         \"leaf_size\": [1, 2, 3, 5],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "#         \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "    }), \n",
    "#     \"svc\": (SVC, {\n",
    "#         \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "#         \"C\": [0.1, 1, 10, 100],\n",
    "#         \"gamma\": [0.1, 1, 10, 100],\n",
    "#         \"degree\": [0, 1, 2, 3, 4, 5, 6]\n",
    "#     }), \n",
    "    \"dtree\": (DecisionTreeClassifier, {\n",
    "#         \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"min_samples_split\": [2, 3, 4, 5, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 3, 4, 5]  \n",
    "    }), \n",
    "    \"rforest\": (RandomForestClassifier, {\n",
    "#         \"criterion\": [\"gini\", \"entropy\"],\n",
    "#         \"n_estimators\": [10, 15, 20, 25, 30],\n",
    "        \"min_samples_split\": [2, 3, 4, 5, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 3, 4, 5]\n",
    "    }), \n",
    "    \"logreg\": (LogisticRegression, {\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\": [0.1, 1, 10]\n",
    "    })\n",
    "}\n",
    "\n",
    "param_table = {\n",
    "    \"processed\": (\n",
    "        (X_train_pro, X_test_pro),\n",
    "        dict.fromkeys(model_hyperparams)\n",
    "    ),\n",
    "    \"scaled\": (\n",
    "        (X_train_sca, X_test_sca),\n",
    "        dict.fromkeys(model_hyperparams)\n",
    "    ),\n",
    "    \"reduced\": (\n",
    "        (X_train_red, X_test_red),\n",
    "        dict.fromkeys(model_hyperparams)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Optimized Hyperparameters for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKING ON DATASET: SCALED\n",
      "\tFITTING MODEL: KNN\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: DTREE\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: RFOREST\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: LOGREG\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "WORKING ON DATASET: PROCESSED\n",
      "\tFITTING MODEL: KNN\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: DTREE\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: RFOREST\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: LOGREG\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "WORKING ON DATASET: REDUCED\n",
      "\tFITTING MODEL: KNN\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: DTREE\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: RFOREST\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n",
      "\tFITTING MODEL: LOGREG\n",
      "\t\tMODEL FITTED SUCCESSFULLY.\n"
     ]
    }
   ],
   "source": [
    "for dataset in param_table.keys():\n",
    "    print(\"WORKING ON DATASET: {}\".format(dataset.upper()))\n",
    "    for model in model_hyperparams.keys():\n",
    "        print(\"\\tFITTING MODEL: {}\".format(model.upper()))\n",
    "        classifier = model_hyperparams[model][0]()\n",
    "        clf_grid = GridSearchCV(classifier, model_hyperparams[model][1], cv=5, verbose=0)\n",
    "        optimal_model = clf_grid.fit(param_table[dataset][0][0], y_train_pro)\n",
    "        param_table[dataset][1][model] = optimal_model.best_estimator_.get_params()\n",
    "        print(\"\\t\\tMODEL FITTED SUCCESSFULLY.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attain Generalized Accuracy Scores for Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Data Case [SCALED] with Model [KNN] -> STANDARD ACCURACY SCORE: 0.6680.\n",
      "For Data Case [SCALED] with Model [DTREE] -> STANDARD ACCURACY SCORE: 0.2456.\n",
      "For Data Case [SCALED] with Model [RFOREST] -> STANDARD ACCURACY SCORE: 0.3367.\n",
      "For Data Case [SCALED] with Model [LOGREG] -> STANDARD ACCURACY SCORE: 0.2962.\n",
      "For Data Case [PROCESSED] with Model [KNN] -> STANDARD ACCURACY SCORE: 0.6319.\n",
      "For Data Case [PROCESSED] with Model [DTREE] -> STANDARD ACCURACY SCORE: 0.2456.\n",
      "For Data Case [PROCESSED] with Model [RFOREST] -> STANDARD ACCURACY SCORE: 0.3558.\n",
      "For Data Case [PROCESSED] with Model [LOGREG] -> STANDARD ACCURACY SCORE: 0.3062.\n",
      "For Data Case [REDUCED] with Model [KNN] -> STANDARD ACCURACY SCORE: 0.2513.\n",
      "For Data Case [REDUCED] with Model [DTREE] -> STANDARD ACCURACY SCORE: 0.2574.\n",
      "For Data Case [REDUCED] with Model [RFOREST] -> STANDARD ACCURACY SCORE: 0.2624.\n",
      "For Data Case [REDUCED] with Model [LOGREG] -> STANDARD ACCURACY SCORE: 0.2637.\n"
     ]
    }
   ],
   "source": [
    "for dataset in param_table.keys():\n",
    "    for model in model_hyperparams.keys():\n",
    "        get_model_accuracy_metrics(model, dataset, param_table[dataset][1][model], scoring=\"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attain F1 Accuracy Scores for Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Data Case [SCALED] with Model [KNN] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.6680.\n",
      "For Data Case [SCALED] with Model [DTREE] & Optimal Average Parameter [WEIGHTED] -> F1 ACCURACY SCORE 0.2457.\n",
      "For Data Case [SCALED] with Model [RFOREST] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.3544.\n",
      "For Data Case [SCALED] with Model [LOGREG] & Optimal Average Parameter [MACRO] -> F1 ACCURACY SCORE 0.2971.\n",
      "For Data Case [PROCESSED] with Model [KNN] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.6319.\n",
      "For Data Case [PROCESSED] with Model [DTREE] & Optimal Average Parameter [WEIGHTED] -> F1 ACCURACY SCORE 0.2457.\n",
      "For Data Case [PROCESSED] with Model [RFOREST] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.3705.\n",
      "For Data Case [PROCESSED] with Model [LOGREG] & Optimal Average Parameter [MACRO] -> F1 ACCURACY SCORE 0.3118.\n",
      "For Data Case [REDUCED] with Model [KNN] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.2513.\n",
      "For Data Case [REDUCED] with Model [DTREE] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.2604.\n",
      "For Data Case [REDUCED] with Model [RFOREST] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.2574.\n",
      "For Data Case [REDUCED] with Model [LOGREG] & Optimal Average Parameter [MICRO] -> F1 ACCURACY SCORE 0.2637.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakashsudhakar/anaconda3/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/aakashsudhakar/anaconda3/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/aakashsudhakar/anaconda3/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/aakashsudhakar/anaconda3/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for dataset in param_table.keys():\n",
    "    for model in model_hyperparams.keys():\n",
    "        get_model_accuracy_metrics(model, dataset, param_table[dataset][1][model], scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For both generalized and F1 accuracy, the best performing model appears to be the _k-Nearest Neighbors_ Classifier Algorithm on the Scaled Data, with an approximate accuracy of `~66.8%`. \n",
    "\n",
    "Methods to improve our accuracy are as follows:\n",
    "- Use different data scaling/normalization techniques to retain more signal.\n",
    "- Implement more fine-tuned encoding schemas, including frequency-based and categorical encoding.\n",
    "- Try different variations of abstract classical machine learning models (e.g. forest variants).\n",
    "- Create a deep learning approach to learn and retain more signal while dropping noisy data.\n",
    "- Run more hyperparameter tuning samples to attain more optimal models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section D: Deep Learning <a name=\"section-D\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Appendix A: Supplementary Custom Objects <a name=\"appendix-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A[1]: Model Accuracy Metric Function.\n",
    "\n",
    "Function to run a machine learning model with optimized hyperparameters on user-specified dataset and attain generalized or F1 accuracy metrics, as well as potentially attaining a confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy_metrics(model, variant, hyperparams, scoring=\"standard\"):\n",
    "    \"\"\" Function to get descriptively statistical accuracy metrics using cross-validation on machine learning model prediction. \"\"\"\n",
    "    X_train, X_test = param_table[variant][0]\n",
    "    y_train, y_test = y_train_pro, y_test_pro\n",
    "    \n",
    "    classifier = model_hyperparams[model][0](**param_table[variant][1][model])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cmat = confusion_matrix(y_pred, y_test)\n",
    "    if scoring == \"standard\":\n",
    "        optimal_accuracy = classifier.score(X_test, y_test)\n",
    "        print(\"For Data Case [{}] with Model [{}] -> {} ACCURACY SCORE: {:.4f}.\".format(variant.upper(), \n",
    "                                                                                        model.upper(), \n",
    "                                                                                        scoring.upper(),\n",
    "                                                                                        optimal_accuracy))\n",
    "    if scoring == \"f1\":\n",
    "        optimal_accuracy, optimal_avg, averages = float(), str(), [\"macro\", \"micro\", \"weighted\"]\n",
    "        for average in averages:\n",
    "            acc = f1_score(y_test, y_pred, average=average)\n",
    "            if acc > optimal_accuracy:\n",
    "                optimal_avg, optimal_accuracy = average, acc\n",
    "        print(\"For Data Case [{}] with Model [{}] & Optimal Average Parameter [{}] -> {} ACCURACY SCORE {:.4f}.\".format(variant.upper(),\n",
    "                                                                                                                        model.upper(),\n",
    "                                                                                                                        optimal_avg.upper(),\n",
    "                                                                                                                        scoring.upper(),\n",
    "                                                                                                                        optimal_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
