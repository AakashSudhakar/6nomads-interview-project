{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we analyze the given external datasets through a **preprocessing** lens: we manipulate, curate, and prepare data to better understand what we're dealing with and to prepare our input data for more advanced prediction-driven modifications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”µ TABLE OF CONTENTS ðŸ”µ <a name=\"TOC\"></a>\n",
    "\n",
    "Use this **table of contents** to navigate the various sections of the preprocessing notebook.\n",
    "\n",
    "#### 1. [Section A: Imports and Initializations](#section-A)\n",
    "\n",
    "    All necessary imports and object instantiations for data preprocessing.\n",
    "    \n",
    "#### 2. [Section B: Manipulating Our Datasets](#section-B)\n",
    "\n",
    "    Data manipulation operations, including null value removal/imputation, \n",
    "    data splitting/merging, and data frequency generation.\n",
    "\n",
    "#### 3. [Section C: Visualizing Trends Across Our Data](#section-C)\n",
    "\n",
    "    Data visualizations to outline trends and patterns inherent across our data\n",
    "    that may mandate further analysis.\n",
    "\n",
    "#### 4. [Section D: Saving Our Interim Datasets](#section-D)\n",
    "\n",
    "    Saving preprocessed data states for further access.\n",
    "\n",
    "#### 5. [Appendix A: Supplementary Custom Objects](#appendix-A)\n",
    "\n",
    "    Custom Python object architectures used throughout the data preprocessing.\n",
    "\n",
    "#### 6. [Appendix B: Data Dictionary](#appendix-B)\n",
    "\n",
    "    Data dictionary representation for our dataset.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section A: Imports and Initializations <a name=\"section-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Importations for Data Manipulation and Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Algorithmic Structures for Data Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../structures/\")\n",
    "# from dataset_preprocessor import Dataset_Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate our Preprocessor Engine\n",
    "\n",
    "Custom Preprocessor Class for Directed Data Manipulation.\n",
    "\n",
    "**NOTE**: Please refer to _Appendix A: Supplementary Custom Objects_ for instructions on how to view the fully implemented dataset preprocessor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = Dataset_Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section B: Manipulating Our Datasets <a name=\"section-B\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ”¸ CHECKPOINT ðŸ”¸\n",
    "\n",
    "**Interim data ready to save.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section C: Visualizing Trends Across Our Data <a name=\"section-C\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Section D: Saving Our Interim Datasets <a name=\"section-D\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Appendix A: Supplementary Custom Objects <a name=\"appendix-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A[1]: 6Nomads Dataset Preprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the **Data Preprocessor Engine**, please follow the following steps:\n",
    "\n",
    "1. Navigate to the `structures` sibling directory. \n",
    "2. Access the `dataset_preprocessor.py` file. \n",
    "3. View the `Dataset_Preprocessor()` object architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE_: **Creating Preprocessor Engine in Notebook Until Further Separation of Concerns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Preprocessor(object):\n",
    "    \"\"\" Class object instance for preprocessing and cleaning 6Nomads data for predictive analytics. \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializer method for object instance creation. \"\"\"\n",
    "        self.REL_PATH_TO_EXT_DATA_TRAIN = \"../data/external/train.csv\"\n",
    "        self.REL_PATH_TO_EXT_DATA_TEST = \"../data/external/test.csv\"\n",
    "        \n",
    "    def load_data(self, which=\"both\"):\n",
    "        \"\"\" \n",
    "        Instance method to load in dataset(s) into conditionally separated/joined Pandas DataFrame(s). \n",
    "        \n",
    "        INPUTS:\n",
    "            {which}:\n",
    "                - str(both): Reads in training and testing data files as tuple of individual DataFrames. (DEFAULT)\n",
    "                - str(all): Reads in training and testing data files as single conjoined DataFrame.\n",
    "                - str(train): Reads in training data file as single DataFrame.\n",
    "                - str(test): Reads in testing data file as single DataFrame.\n",
    "                \n",
    "        OUTPUTS:\n",
    "            pandas.DataFrame: Single or multiple Pandas DataFrame object(s) containing relevant data.\n",
    "        \"\"\"\n",
    "        # Validate conditional data loading arguments\n",
    "        if which not in [\"all\", \"both\", \"train\", \"test\"]:\n",
    "            raise ValueError(\"ERROR: Expected value in range:\\n - all\\n - both\\n - train\\n - test\\n\\nReceived:\\n - {}\".format(which))\n",
    "        \n",
    "        # Independently load training data\n",
    "        if which == \"train\":\n",
    "            return pd.read_csv(self.REL_PATH_TO_EXT_DATA_TRAIN)\n",
    "        \n",
    "        # Independently load testing data\n",
    "        if which == \"test\":\n",
    "            return pd.read_csv(self.REL_PATH_TO_EXT_DATA_TEST)\n",
    "        else:\n",
    "            df_train = pd.read_csv(self.REL_PATH_TO_EXT_DATA_TRAIN)\n",
    "            df_test = pd.read_csv(self.REL_PATH_TO_EXT_DATA_TEST)\n",
    "            \n",
    "            # Load merged training and testing data\n",
    "            if which == \"all\":\n",
    "                return pd.concat([df_train, df_test], keys=[\"train\", \"test\"], sort=True)\n",
    "            \n",
    "            # Load separated training and testing data (DEFAULT)\n",
    "            if which == \"both\":\n",
    "                return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Appendix B: Data Dictionary <a name=\"appendix-B\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
