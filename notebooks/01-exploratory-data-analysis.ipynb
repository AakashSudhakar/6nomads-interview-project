{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we analyze the given external datasets through a **preprocessing** lens: we manipulate, curate, and prepare data to better understand what we're dealing with and to prepare our input data for more advanced prediction-driven modifications.\n",
    "\n",
    "- **NOTE**: Before working through this notebook, please ensure that you have all necessary dependencies as denoted in [Section A: Imports and Initializations](#section-A) of this notebook.\n",
    "\n",
    "- **NOTE**: Before working through Sections A-D of this notebook, please run all code cells in [Appendix A: Supplementary Custom Objects](#appendix-A) to ensure that all relevant functions and objects are appropriately instantiated and ready for use.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔵 TABLE OF CONTENTS 🔵 <a name=\"TOC\"></a>\n",
    "\n",
    "Use this **table of contents** to navigate the various sections of the preprocessing notebook.\n",
    "\n",
    "#### 1. [Section A: Imports and Initializations](#section-A)\n",
    "\n",
    "    All necessary imports and object instantiations for data preprocessing.\n",
    "    \n",
    "#### 2. [Section B: Manipulating Our Datasets](#section-B)\n",
    "\n",
    "    Data manipulation operations, including null value removal/imputation, \n",
    "    data splitting/merging, and data frequency generation.\n",
    "\n",
    "#### 3. [Section C: Visualizing Trends Across Our Data](#section-C)\n",
    "\n",
    "    Data visualizations to outline trends and patterns inherent across our data\n",
    "    that may mandate further analysis.\n",
    "\n",
    "#### 4. [Section D: Saving Our Interim Datasets](#section-D)\n",
    "\n",
    "    Saving preprocessed data states for further access.\n",
    "\n",
    "#### 5. [Appendix A: Supplementary Custom Objects](#appendix-A)\n",
    "\n",
    "    Custom Python object architectures used throughout the data preprocessing.\n",
    "\n",
    "#### 6. [Appendix B: Data Dictionary](#appendix-B)\n",
    "\n",
    "    Data dictionary representation for our dataset.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Section A: Imports and Initializations <a name=\"section-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Importations for Data Manipulation and Visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Algorithmic Structures for Data Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../structures/\")\n",
    "from custom_structures import corrplot_\n",
    "from dataset_preprocessor import Dataset_Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate our Preprocessor Engine\n",
    "\n",
    "Custom Preprocessor Class for Directed Data Manipulation.\n",
    "\n",
    "**NOTE**: Please refer to _Appendix A: Supplementary Custom Objects_ for instructions on how to view the fully implemented dataset preprocessor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = Dataset_Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Section B: Manipulating Our Datasets <a name=\"section-B\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Our Raw Data Into Conditional DataFrame(s)\n",
    "\n",
    "**Call** `.load_data()` **method to load in all conditionally separated external datasets.**\n",
    "\n",
    "_NOTE_: Currently loading in both datasets independently using defaulted condition `which=\"both\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train, df_test) = preproc.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Unique Values Across Each Feature in Training Dataset.\n",
    "\n",
    "**Call the** `get_uniques()` **custom function to identify unique values across all input features for dataset(s).**\n",
    "\n",
    "_NOTE_: Currently identifying unique data values across all features in dataset using defaulted conditions `features=None` and `how=\"value\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_train, uniques_test = get_uniques(df_train), get_uniques(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Which Features Across Training/Testing Data Contain `NaN` (Null) Values.\n",
    "\n",
    "_NOTE_: Null values are denoted as `np.nan` (float) datatypes and will appear as `<type 'float'>` data notations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "floating_features_train = identify_typed_features(uniques_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _RESULT_: No null values detected across any features in training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -28\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': 41\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -11\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -10\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -19\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -5.1\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -33\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -3\n",
      "IDENTIFIED FEATURE OF TYPE '<type 'float'>': -2\n"
     ]
    }
   ],
   "source": [
    "floating_features_test = identify_typed_features(uniques_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _RESULT_: Null values potentially detected across nine (9) features in testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm Null Value Presence Across Identified \"Floating\" Features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28     False\n",
       "41      False\n",
       "-11     False\n",
       "-10     False\n",
       "-19     False\n",
       "-5.1    False\n",
       "-33     False\n",
       "-3      False\n",
       "-2      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_null_metrics(df_test, \n",
    "                 subset=floating_features_test, \n",
    "                 metric=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Proportion of Null Values Across Each Identified \"Floating\" Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28     0.0\n",
       "41      0.0\n",
       "-11     0.0\n",
       "-10     0.0\n",
       "-19     0.0\n",
       "-5.1    0.0\n",
       "-33     0.0\n",
       "-3      0.0\n",
       "-2      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_null_metrics(df_test, \n",
    "                 subset=floating_features_test, \n",
    "                 metric=\"percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute Null Values Across Floating Features\n",
    "\n",
    "**NOTE**: Since null values are highly sparse across our data (highest frequent occurrency is ~0.1%) and the size of our data is not small, we can safely drop null values rather than performing advanced imputation (e.g. _null value flagging_, _mean/mode replacement_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null imputation has successfully completed.\n"
     ]
    }
   ],
   "source": [
    "preproc.null_imputer(df_test, \n",
    "                     subset=floating_features_test, \n",
    "                     method=\"drop\", \n",
    "                     na_filter=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reencode Alphabetical Features for Numerical Encoding Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKUP_TABLE_ALPHANUMERIC = {\n",
    "    1: \"A\", \n",
    "    2: \"B\", \n",
    "    3: \"C\", \n",
    "    4: \"D\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE_: Feature encoding occurs inplace; if condition `drop_og` is `True`, then rerunning method call will result in errors due to dropped target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.feature_encoder(df_train,\n",
    "                        target=\"C\",\n",
    "                        lookup_table=LOOKUP_TABLE_ALPHANUMERIC,\n",
    "                        drop_og=True)\n",
    "\n",
    "preproc.feature_encoder(df_test,\n",
    "                        target=\"A\",\n",
    "                        lookup_table=LOOKUP_TABLE_ALPHANUMERIC,\n",
    "                        drop_og=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🔸 CHECKPOINT 🔸\n",
    "\n",
    "**Interim data ready to save.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Section C: Visualizing Trends Across Our Data <a name=\"section-C\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ⭐️ _TODO_: Include visualizations towards end of pipeline architectural creation. ⭐️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Section D: Saving Our Interim Datasets <a name=\"section-D\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interim datasets are data states directly after preprocessing, where data is designated for curation and manipulation prior to target vs. non-target handling.\n",
    "\n",
    "#### Save Current (Preprocessed) Data States to Interim Datasets\n",
    "\n",
    "**Call** `.save_dataset()` **method to save data state to interim folder for processing accessability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_PATH_TO_ITM_DATA = \"../data/interim/\"\n",
    "FILENAME_TRAINING, FILENAME_TESTING = \"train_i\", \"test_i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.save_dataset(df_train, REL_PATH_TO_ITM_DATA + FILENAME_TRAINING)\n",
    "preproc.save_dataset(df_test, REL_PATH_TO_ITM_DATA + FILENAME_TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Appendix A: Supplementary Custom Objects <a name=\"appendix-A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A[1]: 6Nomads Dataset Preprocessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the **Data Preprocessor Engine**, please follow the following steps:\n",
    "\n",
    "1. Navigate to the `structures` sibling directory. \n",
    "2. Access the `dataset_preprocessor.py` file. \n",
    "3. View the `Dataset_Preprocessor()` object architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NOTE_: **Creating Preprocessor Engine in Notebook Until Further Separation of Concerns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A[2]: Function to Obtain Relevant Unique Values or Data Types from Feature(s) Across Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniques(dataset, features=None, how=\"both\"):\n",
    "    \"\"\"\n",
    "    Custom function that analyzes a dataset's given feature(s) and returns all unique values or data types\n",
    "    across each inputted feature.\n",
    "    \n",
    "    INPUTS:\n",
    "        {features}:\n",
    "            - NoneType(None): Sets function to use all features across dataset. (DEFAULT)\n",
    "            - str: Single referenced feature in dataset.\n",
    "            - list: List of referenced features in dataset.\n",
    "        {how}:\n",
    "            - str(both): Identifies both unique data types and values. (DEFAULT)\n",
    "            - str(dtype): Identifies unique data types.\n",
    "            - str(value): Identifies unique data values.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        dict(uniques): Dictionary structure mapping each input feature to relevantly identified unique values/types.\n",
    "    \"\"\"\n",
    "    # Validate selected features argument\n",
    "    if features is not None and type(features) not in [str, list]:\n",
    "        raise TypeError(\"ERROR: Inappropriate data type passed to argument `features`.\\n\\nExpected type in range:\\n - NoneType\\n - str()\\n - list()\\n\\nActual:\\n - {}\".format(str(type(features))))\n",
    "    \n",
    "    # Validate unique identifier argument\n",
    "    if how not in [\"both\", \"dtype\", \"value\"]:\n",
    "        raise ValueError(\"ERROR: Inappropriate value passed to argument `how`.\\n\\nExpected value in range:\\n - both\\n - dtype\\n - value\\n\\nActual:\\n - {}\".format(how))\n",
    "        \n",
    "    # Reformat `features` object into list\n",
    "    if features is None:\n",
    "        features = dataset.columns.tolist()\n",
    "    if type(features) == str:\n",
    "        features = [features]\n",
    "        \n",
    "    # Create uniques object and iteratively map each feature to associated unique data\n",
    "    uniques = dict()\n",
    "    # Create dictionary object associating feature(s) and unique data types and values\n",
    "    if how == \"both\":\n",
    "        unique_types, unique_values = dict(), dict()\n",
    "        for feature in features:\n",
    "            unique_types[feature] = list(set(map(type, dataset[feature])))\n",
    "            unique_values[feature] = sorted(dataset[feature].unique().tolist())\n",
    "        unique_components = [unique_types, unique_values]\n",
    "        for feature in unique_types.keys():\n",
    "            uniques[feature] = {\"dtypes\": unique_components[0][feature], \"values\": unique_components[1][feature]}\n",
    "    else:\n",
    "        for feature in features:\n",
    "            # Create dictionary object associating feature(s) and unique data types\n",
    "            if how == \"dtype\":\n",
    "                uniques[feature] = list(set(map(type, dataset[feature])))\n",
    "            # Create dictionary object associating feature(s) and unique values\n",
    "            if how == \"value\":\n",
    "                uniques[feature] = sorted(dataset[feature].unique().tolist())\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A[3]: Function to Identify and Return Features Containing Unique Input Data Types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_typed_features(uniques, dtype=float):\n",
    "    \"\"\"\n",
    "    Custom function that extracts features from previously generated unique feature data\n",
    "    based on whether or not feature includes user-specified data type.\n",
    "    \n",
    "    INPUTS: \n",
    "        {uniques}:\n",
    "            - dict: Dictionary object of feature associations generated by `get_uniques()`.\n",
    "        {dtype}:\n",
    "            - type(float): Float data type. (DEFAULT)\n",
    "            - type(int): Integer data type.\n",
    "            - type(str): String data type.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        list(typed_features): List of feature names corresponding to identified user-specified data types.\n",
    "    \"\"\"\n",
    "    typed_features = list()\n",
    "    for key in uniques.keys():\n",
    "        if uniques[key][\"dtypes\"][0] == dtype:\n",
    "            print(\"IDENTIFIED FEATURE OF TYPE '{}': {}\".format(str(dtype), key))\n",
    "            typed_features.append(key)\n",
    "    return typed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A[4]: Function to Calculate Null/Missing Metrics of Given Feature Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_metrics(dataset, subset=None, metric=\"percent\"):\n",
    "    \"\"\"\n",
    "    Custom function that produces series of associated features and metrics related to\n",
    "    presence and proportion of null/missing values.\n",
    "    \n",
    "    INPUTS:\n",
    "        {dataset}:\n",
    "            - pd.DataFrame: Single input dataset.\n",
    "        {subset}:\n",
    "            - NoneType: If None, all features are used for null metric evaluation. (DEFAULT)\n",
    "            - list: Array of features across data to consider; others are ignored.\n",
    "        {metric}:\n",
    "            - str(percent): Determines calculation of relative proportions of null values per feature. (DEFAULT)\n",
    "            - str(count): Determines calculation of absolute count of null values per feature.\n",
    "            - str(binary): Determines identification of whether or not any null values occur per feature.\n",
    "    \n",
    "    OUTPUTS:\n",
    "        pd.Series: Series of associated feature names and relative null value prevalence metrics.\n",
    "    \"\"\"\n",
    "    # Validate `subset` keyword argument\n",
    "    if subset is None:\n",
    "        subset = dataset.columns.tolist()\n",
    "        \n",
    "    # Calculate percentages for null values across each input feature\n",
    "    if metric == \"percent\":\n",
    "        return dataset[subset].isna().sum() / len(dataset)\n",
    "    # Calculate total counts of null values across each input feature\n",
    "    elif metric == \"count\":\n",
    "        return dataset[subset].isna().sum()\n",
    "    # Determine True/False based on null value presence across each input feature\n",
    "    elif metric == \"binary\":\n",
    "        binarized_metrics = list()\n",
    "        for feature in subset:\n",
    "            nulls_in_feature = dataset[feature].isna().values.any()\n",
    "            binarized_metrics.append((feature, nulls_in_feature))\n",
    "        binarized_metrics_series = list(zip(*binarized_metrics))\n",
    "        return pd.Series(binarized_metrics_series[1], index=binarized_metrics_series[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔹 Appendix B: Data Dictionary <a name=\"appendix-B\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [(back to top)](#TOC)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
